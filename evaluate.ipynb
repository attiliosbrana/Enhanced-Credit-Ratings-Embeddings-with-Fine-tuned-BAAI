{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.schema import TextNode\n",
    "from llama_index.embeddings import OpenAIEmbedding\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load environment variables for API key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Load datasets\n",
    "TRAIN_DATASET_FPATH = './data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = './data/val_dataset.json'\n",
    "\n",
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation function using hit rate metric\n",
    "def evaluate(dataset, embed_model, top_k=5, verbose=False):\n",
    "    corpus = dataset['corpus']\n",
    "    queries = dataset['queries']\n",
    "    relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "    nodes = [TextNode(id_=id_, text=text) for id_, text in corpus.items()]\n",
    "    index = VectorStoreIndex(nodes, service_context=service_context, show_progress=True)\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "\n",
    "    eval_results = []\n",
    "    for query_id, query in tqdm(queries.items()):\n",
    "        retrieved_nodes = retriever.retrieve(query)\n",
    "        retrieved_ids = [node.node.node_id for node in retrieved_nodes]\n",
    "        expected_id = relevant_docs[query_id][0]\n",
    "        is_hit = expected_id in retrieved_ids\n",
    "        \n",
    "        eval_result = {\n",
    "            'is_hit': is_hit,\n",
    "            'retrieved': retrieved_ids,\n",
    "            'expected': expected_id,\n",
    "            'query': query_id,\n",
    "        }\n",
    "        eval_results.append(eval_result)\n",
    "    return eval_results\n",
    "\n",
    "# Define the evaluation function using InformationRetrievalEvaluator\n",
    "def evaluate_st(dataset, model_id, name):\n",
    "    corpus = dataset['corpus']\n",
    "    queries = dataset['queries']\n",
    "    relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "    evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs, name=name)\n",
    "    model = SentenceTransformer(model_id)\n",
    "    return evaluator(model, output_path='results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cc3c9424c949d9b43acb01148771f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581f47bdd7b8476697dc838ed5c15b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate for ada: 0.6714784633294528\n"
     ]
    }
   ],
   "source": [
    "# Run evaluations\n",
    "ada = OpenAIEmbedding(api_key=openai_api_key)\n",
    "ada_val_results = evaluate(val_dataset, ada)\n",
    "df_ada = pd.DataFrame(ada_val_results)\n",
    "hit_rate_ada = df_ada['is_hit'].mean()\n",
    "print(f'Hit rate for ada: {hit_rate_ada}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40da0b41b7514ca4a0fd5ff52cffc081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6b15c9fd964556a16a9411a60a5f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate for BAAI/bge-large-en: 0.6519208381839348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.511669801273743"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For BAAI/bge-large-en (assuming BAAIEmbedding is your class to handle BAAI embeddings)\n",
    "bge_large = \"local:BAAI/bge-large-en\"\n",
    "bge_large_val_results = evaluate(val_dataset, bge_large)\n",
    "df_bge_large = pd.DataFrame(bge_large_val_results)\n",
    "hit_rate_bge_large = df_bge_large['is_hit'].mean()\n",
    "print(f'Hit rate for BAAI/bge-large-en: {hit_rate_bge_large}')\n",
    "\n",
    "# For BAAI/bge-large-en using InformationRetrievalEvaluator\n",
    "evaluate_st(val_dataset, \"BAAI/bge-large-en\", name='bge_large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f14c740146478c9474e8804124c649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd7f90ccbdd46b8a022a4d615050e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate for finetuned model: 0.739464493597206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6542465972976504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For finetuned model\n",
    "finetuned = \"local:exp_finetune_optimal\"\n",
    "val_results_finetuned = evaluate(val_dataset, finetuned)\n",
    "df_finetuned = pd.DataFrame(val_results_finetuned)\n",
    "hit_rate_finetuned = df_finetuned['is_hit'].mean()\n",
    "print(f'Hit rate for finetuned model: {hit_rate_finetuned}')\n",
    "\n",
    "# For finetuned model using InformationRetrievalEvaluator\n",
    "evaluate_st(val_dataset, \"exp_finetune_optimal\", name='finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada['model'] = 'ada'\n",
    "df_bge_large['model'] = 'bge_large'\n",
    "df_finetuned['model'] = 'fine_tuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_hit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.671478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bge_large</th>\n",
       "      <td>0.651921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_tuned</th>\n",
       "      <td>0.739464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              is_hit\n",
       "model               \n",
       "ada         0.671478\n",
       "bge_large   0.651921\n",
       "fine_tuned  0.739464"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat([df_ada, df_bge_large, df_finetuned])\n",
    "df_all.groupby('model').mean('is_hit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of finetuned model over ada: 10.12%\n",
      "Improvement of finetuned model over BAAI/bge-large-en: 13.43%\n"
     ]
    }
   ],
   "source": [
    "# Improvement of finetuned model over ada\n",
    "print(f'Improvement of finetuned model over ada: {round((hit_rate_finetuned - hit_rate_ada) / hit_rate_ada * 100, 2)}%')\n",
    "\n",
    "# Improvement of finetuned model over BAAI/bge-large-en\n",
    "print(f'Improvement of finetuned model over BAAI/bge-large-en: {round((hit_rate_finetuned - hit_rate_bge_large) / hit_rate_bge_large * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_st_bge = pd.read_csv('results/Information-Retrieval_evaluation_bge_large_results.csv')\n",
    "df_st_finetuned = pd.read_csv('results/Information-Retrieval_evaluation_finetuned_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>steps</th>\n",
       "      <th>cos_sim-Accuracy@1</th>\n",
       "      <th>cos_sim-Accuracy@3</th>\n",
       "      <th>cos_sim-Accuracy@5</th>\n",
       "      <th>cos_sim-Accuracy@10</th>\n",
       "      <th>cos_sim-Precision@1</th>\n",
       "      <th>cos_sim-Recall@1</th>\n",
       "      <th>cos_sim-Precision@3</th>\n",
       "      <th>cos_sim-Recall@3</th>\n",
       "      <th>...</th>\n",
       "      <th>dot_score-Recall@1</th>\n",
       "      <th>dot_score-Precision@3</th>\n",
       "      <th>dot_score-Recall@3</th>\n",
       "      <th>dot_score-Precision@5</th>\n",
       "      <th>dot_score-Recall@5</th>\n",
       "      <th>dot_score-Precision@10</th>\n",
       "      <th>dot_score-Recall@10</th>\n",
       "      <th>dot_score-MRR@10</th>\n",
       "      <th>dot_score-NDCG@10</th>\n",
       "      <th>dot_score-MAP@100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bge_large</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.428172</td>\n",
       "      <td>0.562747</td>\n",
       "      <td>0.609313</td>\n",
       "      <td>0.665076</td>\n",
       "      <td>0.428172</td>\n",
       "      <td>0.428172</td>\n",
       "      <td>0.187582</td>\n",
       "      <td>0.562747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092782</td>\n",
       "      <td>0.053628</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>0.039558</td>\n",
       "      <td>0.197788</td>\n",
       "      <td>0.024517</td>\n",
       "      <td>0.245169</td>\n",
       "      <td>0.136886</td>\n",
       "      <td>0.162539</td>\n",
       "      <td>0.147194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fine_tuned</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.584750</td>\n",
       "      <td>0.702678</td>\n",
       "      <td>0.739464</td>\n",
       "      <td>0.776251</td>\n",
       "      <td>0.584750</td>\n",
       "      <td>0.584750</td>\n",
       "      <td>0.234226</td>\n",
       "      <td>0.702678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559953</td>\n",
       "      <td>0.228328</td>\n",
       "      <td>0.684983</td>\n",
       "      <td>0.144587</td>\n",
       "      <td>0.722934</td>\n",
       "      <td>0.076554</td>\n",
       "      <td>0.765541</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>0.634284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            epoch  steps  cos_sim-Accuracy@1  cos_sim-Accuracy@3  \\\n",
       "model                                                              \n",
       "bge_large      -1     -1            0.428172            0.562747   \n",
       "fine_tuned     -1     -1            0.584750            0.702678   \n",
       "\n",
       "            cos_sim-Accuracy@5  cos_sim-Accuracy@10  cos_sim-Precision@1  \\\n",
       "model                                                                      \n",
       "bge_large             0.609313             0.665076             0.428172   \n",
       "fine_tuned            0.739464             0.776251             0.584750   \n",
       "\n",
       "            cos_sim-Recall@1  cos_sim-Precision@3  cos_sim-Recall@3  ...  \\\n",
       "model                                                                ...   \n",
       "bge_large           0.428172             0.187582          0.562747  ...   \n",
       "fine_tuned          0.584750             0.234226          0.702678  ...   \n",
       "\n",
       "            dot_score-Recall@1  dot_score-Precision@3  dot_score-Recall@3  \\\n",
       "model                                                                       \n",
       "bge_large             0.092782               0.053628            0.160885   \n",
       "fine_tuned            0.559953               0.228328            0.684983   \n",
       "\n",
       "            dot_score-Precision@5  dot_score-Recall@5  dot_score-Precision@10  \\\n",
       "model                                                                           \n",
       "bge_large                0.039558            0.197788                0.024517   \n",
       "fine_tuned               0.144587            0.722934                0.076554   \n",
       "\n",
       "            dot_score-Recall@10  dot_score-MRR@10  dot_score-NDCG@10  \\\n",
       "model                                                                  \n",
       "bge_large              0.245169          0.136886           0.162539   \n",
       "fine_tuned             0.765541          0.630700           0.663444   \n",
       "\n",
       "            dot_score-MAP@100  \n",
       "model                          \n",
       "bge_large            0.147194  \n",
       "fine_tuned           0.634284  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_st_bge['model'] = 'bge_large'\n",
    "df_st_finetuned['model'] = 'fine_tuned'\n",
    "df_st_all = pd.concat([df_st_bge, df_st_finetuned])\n",
    "df_st_all = df_st_all.set_index('model')\n",
    "df_st_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e5dfb6a2734642b99237527a578e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/4293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e429ec77e0494a985eec1b81876a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8590 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit rate for finetuned model: 0.769383003492433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6953220765652576"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For finetuned model\n",
    "finetuned = \"local:exp_finetune_entire_dataset\"\n",
    "val_results_finetuned = evaluate(val_dataset, finetuned)\n",
    "df_finetuned = pd.DataFrame(val_results_finetuned)\n",
    "hit_rate_finetuned = df_finetuned['is_hit'].mean()\n",
    "print(f'Hit rate for finetuned model: {hit_rate_finetuned}')\n",
    "\n",
    "# For finetuned model using InformationRetrievalEvaluator\n",
    "evaluate_st(val_dataset, \"exp_finetune_entire_dataset\", name='finetuned_entire_dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
